<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jieun Song  송지은 on Jieun Song  송지은</title>
    <link>/</link>
    <description>Recent content in Jieun Song  송지은 on Jieun Song  송지은</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 15 Oct 2017 00:00:00 +0900</lastBuildDate>
    <atom:link href="/" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Auditory neural tracking and lexical processing of speech in noise: Masker type, spatial location, and language experience</title>
      <link>/publication/jasa/</link>
      <pubDate>Thu, 16 Jul 2020 00:00:00 +0900</pubDate>
      
      <guid>/publication/jasa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The role of listening effort in second-language speech processing</title>
      <link>/talk/snu2019/</link>
      <pubDate>Tue, 03 Dec 2019 00:00:00 +0900</pubDate>
      
      <guid>/talk/snu2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Evaluating Korean learners’ English rhythm proficiency with measures of sentence stress</title>
      <link>/publication/appliedpsycholing/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0900</pubDate>
      
      <guid>/publication/appliedpsycholing/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Native and non-native speech recognition in noise: neural measures of auditory and lexical processing</title>
      <link>/publication/icphs2019/</link>
      <pubDate>Thu, 08 Aug 2019 00:00:00 +0900</pubDate>
      
      <guid>/publication/icphs2019/</guid>
      <description></description>
    </item>
    
    <item>
      <title>언어의 아이들: 아이들은 도대체 어떻게 언어를 배울까?</title>
      <link>/publication/book/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0900</pubDate>
      
      <guid>/publication/book/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Interaction of semantic and prosodic cues in the disambiguation of wh-words in Korean</title>
      <link>/talk/oxford/</link>
      <pubDate>Tue, 29 Jan 2019 00:00:00 +0900</pubDate>
      
      <guid>/talk/oxford/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Listening effort during speech perception enhances auditory and lexical processing for non-native listeners and accents</title>
      <link>/publication/cognition/</link>
      <pubDate>Mon, 01 Oct 2018 00:00:00 +0900</pubDate>
      
      <guid>/publication/cognition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Privacy Policy</title>
      <link>/privacy/</link>
      <pubDate>Thu, 28 Jun 2018 00:00:00 +0900</pubDate>
      
      <guid>/privacy/</guid>
      <description>&lt;p&gt;&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Exploring cortical and subcortical responses to continuous speech</title>
      <link>/talk/aesop/</link>
      <pubDate>Thu, 10 May 2018 00:00:00 +0900</pubDate>
      
      <guid>/talk/aesop/</guid>
      <description></description>
    </item>
    
    <item>
      <title>The effects of adverse conditions on speech recognition by nonnative listeners: Electrophysiological and behavioural evidence</title>
      <link>/publication/phd/</link>
      <pubDate>Sun, 28 Jan 2018 00:00:00 +0900</pubDate>
      
      <guid>/publication/phd/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Automatic Sentence Stress Feedback for Non-native English Learners</title>
      <link>/publication/csl/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0900</pubDate>
      
      <guid>/publication/csl/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Cross-linguistic perception of continuous speech: Neural entrainment to the speech amplitude envelope</title>
      <link>/talk/asa/</link>
      <pubDate>Thu, 01 Dec 2016 00:00:00 +0900</pubDate>
      
      <guid>/talk/asa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>1. Neural processing of speech</title>
      <link>/project/listening-effort/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0900</pubDate>
      
      <guid>/project/listening-effort/</guid>
      <description>&lt;p&gt;Listening to a second language (L2) in real life situations (e.g., a noisy restaurant) can be challenging. Native listeners can flexibly modulate their speech processing to overcome the demands of a noisy environment e.g., use semantic-contextual information to understand what is being said. We know very little, however, about the strategies second-language listeners use to enhance their listening. Using electroencephalography (EEG), my PhD work published in Cognition demonstrated that greater listening effort exerted by L2 listeners enhances their auditory processing, as measured by neural tracking of speech, even though their linguistic processes (e.g., lexical-semantic processing as measured by N400) were less developed than those of native listeners.&lt;/p&gt;

&lt;p&gt;This work subsequently led to a 3-year ESRC research grant on listening effort and multilingual speech communication where I worked as a postdoctoral researcher (PI: Prof. Paul Iverson). You can see a summary of this project here, and please find related work on Publications.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;People feel like they need to &amp;ldquo;listen harder&amp;rdquo; when communicating in a second language, but it isn&amp;rsquo;t clear how this effort changes the brain processes involved in recognising speech. Our initial research has produced a surprising finding; we tested people who were trying to listen to a talker in a noisy background (i.e., a distracting talker), and found that auditory areas of the brain are better at picking out the target talker when people are listening to a second language than their first language. We did this by recording neural activity (electroencephalography; EEG) and measuring how it becomes entrained to the acoustics of speech. Although people would normally be expected to perform better when listening to their first language, we think that second-language listeners had more selective auditory processing because of their additional listening effort. We found related effects for neural measures of word recognition in the same task, and think that we&amp;rsquo;ve found mechanisms that allow second-language learners to partially compensate for their speech recognition difficulties. In this grant project, we will expand our investigation in a series of studies that manipulate the acoustics of speech, and compare how speech is recognised in first and second languages by speakers of English and Korean. Furthermore, we will test adults who learned both languages at the same time when they were young children, adults who learned their second language later in life, and older children who are in the process of learning both languages. Our goals are to understand how people can use listening effort to compensate for their difficulties with second-language speech, and examine how this ability develops and relates to proficiency. This work is important for understanding how people apply their processes and structures for language during everyday speech communication, and is relevant to a wide range of difficult listening conditions (e.g., hearing impairment). The work will also advance our scientific understanding of how new measures of neural entrainment for speech relate to practical aspects of speech recognition.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>2. L2 speech evaluation</title>
      <link>/project/automaticassessment/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0900</pubDate>
      
      <guid>/project/automaticassessment/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hoyounglee.me/&#34; target=&#34;_blank&#34;&gt;Prof. Ho-Young Lee&lt;/a&gt; at Seoul National University and I published an article in Applied Psycholinguistics in 2019 where we proposed using our sentence stress metrics to evaluate the speech rhythm of non-native speakers of English. This study demonstrated that sentence stress scores of Korean learners of English were highly correlated with their overall speaking proficiency. This study started as part of a larger project with computer engineers where we built an automatic sentence stress feedback system for Korean learners of English, and this system was found to improve their pronunciation (published in Computer Speech and Language, 2017).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>3. Child Language Acquisition</title>
      <link>/project/language-acquisition/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0900</pubDate>
      
      <guid>/project/language-acquisition/</guid>
      <description>&lt;p&gt;I have been actively involved in other projects on child language development. I have written a book on child language acquisition with &lt;a href=&#34;https://www.orinst.ox.ac.uk/people/jieun-kiaer&#34; target=&#34;_blank&#34;&gt;Dr. Jieun Kiaer&lt;/a&gt; at the University of Oxford, which was published in 2019 by a highly prestigious publishing house of South Korea, Science Books. While writing this monograph, I became more interested in broader issues on language development and multilingualism. I am collaborating with researchers at Seoul National University and Dr. Jieun Kiaer on a project investigating how Korean children disambiguate wh-words in Korean using prosody. This work is currently under review in &lt;em&gt;Journal of Child Language&lt;/em&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
